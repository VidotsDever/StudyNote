#### MapReduce



Map实现：

```
泛型中的四个参数：进入数据的Key(该行的偏移位置)，进入数据的Value(该行的数据)，出去数据的Key，出去数据的Value
public class WordcountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString();
        String[] words = line.split(" ");
        for (String word : words) {
            context.write(new Text(word), new IntWritable(1));
        }
    }
}
```



Reduce实现：

```
泛型中的四个参数：进入数据的Key(Map阶段出去数据的Key)，进入数据的Value(Map阶段出去数据的Value)，出去数据的Key，出去数据的Value
public class WordcountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        int count = 0;
        Iterator<IntWritable> iterator = values.iterator();
        while (iterator.hasNext()) {
            IntWritable value = iterator.next();
            count += value.get();
        }
        context.write(key, new IntWritable(count));
    }
}
```



#### YARN配置

YARN是集群，主节点是`Resource Manager`,负责任务调度；其它节点是`Node Manager`，负责创建容器，运行程序；

YARN包含在Hadoop中，配置步骤如下(在Hadoop配置好的前提下)，在所有机器上：

```
1. 在etc/hadoop/mapred-site.xml中添加配置
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value> //mapreduce任务运行在哪里
	</property>
2. 在etc/hadoop/yarn-site.xml中添加配置：
	<property>
            <name>yarn.resourcemanager.hostname</name>
        	<value>localhost</value> // 配置Resource Manager
  	</property>
  	<property>
        	<name>yarn.nodemanager.aux-services</name>
        	<value>mapreduce_shuffle</value>
  	</property>
  	
3. 在Resource Manager机器上运行start-yarn.sh启动(在slaves文件中配置了相关节点)

```

访问Web：`IP地址:8088`



#### Job客户端

* 在Windows本地运行，提交到Job到YARN上执行：

```
public class JobSumitter {
    public static void main(String[] args) throws Exception {
        // 在代码中设置JVM系统参数，用于给job对象来获取访问HDFS的用户身份
        System.setProperty("HADOOP_USER_NAME", "vidots");
        Configuration conf = new Configuration();
        // 设置job运行时要访问的默认文件系统
        conf.set("fs.defaultFS", "hdfs://192.168.0.108:9000");
        // 设置job提交到哪去运行
        conf.set("mapreduce.framework.name", "yarn");
        conf.set("yarn.resourcemanager.hostname", "192.168.0.108");
        // 如果要从Windows系统上运行这个job，则需要加这个跨平台提交的参数
        conf.set("mapreduce.app-submission.cross-platform", "true");

        Job job = Job.getInstance(conf);
        // 封装参数：jar包所在的位置 在Windows上执行，需要先编译jar包
        job.setJar("D:\\Dev\\BigData\\simple\\out\\artifacts\\simple_jar\\simple.jar"); // 位置和名称写死
        // job.setJarByClass(JobSumitter.class);
        // 封装参数：本次job所要调用的Mapper实现类、Reducer实现类
        job.setMapperClass(WordcountMapper.class);
        job.setReducerClass(WordcountReducer.class);
        // 封装参数：本次job的Mapper实现类、Reducer实现类产生的结果数据的key、value类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        // 封装参数：本次job要处理的输入数据集所在路径、输出结果的输出路径
        FileInputFormat.setInputPaths(job, new Path("/wordcount/input"));
        FileOutputFormat.setOutputPath(job, new Path("/wordcount/out2")); // 输出路径必须不存在
        // 封装参数：想要启动的reduce task的数量
        job.setNumReduceTasks(1);

        // 提交job给yarn
        boolean result = job.waitForCompletion(true);
    }
}
```



* 在Hadoop集群上执行：

```
hadoop jar myjob.jar com.vidots.simple.JobSummiter
// 在Hadoop集群的某台机器上启动Job任务时，conf中就不需要指定fs.deaultFs和mapreduce.framework.name，因为用hadoop jar xx.jar com.vidots.JobSummiter命令来启动客户端main方法时，hadoop jar会将所在机器上的hadoop安装目录中的jar包和配置文件加入到运行时的classpath中。
// 那么客户端main方法中的new Configuration()语句就会加载classpath中的配置文件，自然就有了相关的配置。
```



* 直接在本地模拟运行(以此种方法运行，一定要配置好Windows版本的Hadoop，不仅要配置HADOOP_HOME，还要将Hadoop目录下的bin加入到Path中)：

```
public class JobSumitter {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        // 设置job运行时要访问的默认文件系统，默认值就是如下配置，可以省略
        conf.set("fs.defaultFS", "file:///");
        // 设置job提交到哪去运行，，默认值就是如下配置，可以省略
        conf.set("mapreduce.framework.name", "local");
       
        Job job = Job.getInstance(conf);
        job.setJarByClass(JobSumitter.class);
        // 封装参数：本次job所要调用的Mapper实现类、Reducer实现类
        job.setMapperClass(WordcountMapper.class);
        job.setReducerClass(WordcountReducer.class);
        // 封装参数：本次job的Mapper实现类、Reducer实现类产生的结果数据的key、value类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        // 封装参数：本次job要处理的输入数据集所在路径、输出结果的输出路径
        FileInputFormat.setInputPaths(job, new Path("D:\Dev\wordcount\input"));
        FileOutputFormat.setOutputPath(job, new Path("D:\dEV\wordcount\out2")); // 输出路径必须不存在
        // 封装参数：想要启动的reduce task的数量
        job.setNumReduceTasks(1);
        boolean result = job.waitForCompletion(true);
    }
}
```

