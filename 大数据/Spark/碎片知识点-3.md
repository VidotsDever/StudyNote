Spark的主要抽象是DataSet，即分布式的数据项的集合；



对于流式应用，在运行Master的时候不能只指定一个线程；因为流在运行的时候，需要开一个新的线程来一直监听数据的获取。



Spark Streaming并不是实时流，而是按照时间切分小批量，一个一个的小批量处理；



Spark Streaming中的编程模型叫做DStream，所有的API都从DStream开始；



Spark Streaming其实就是RDD的API的流式工具，本质上还是RDD，存储和执行过程依然类似RDD;

Structured Streaming其实就是Dataset的API的流式工具，其API和Dataset保持高度一致；



流式的Dataset使用readStream读取外部数据源创建，使用writeStream写入外部存储；

批式的Dataset使用read读取外部数据源创建，使用write写入外部存储；



在Structured Streaming中负责整体流程和执行的驱动引擎叫做`StreamExecution`；























