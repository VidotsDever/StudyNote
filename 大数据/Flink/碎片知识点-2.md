#### Java语言批处理应用

工程创建：

```
利用IDEA创建maven工程：

GroupId=org.apache.flink
ArtifactId=flink-quickstart-java
Version=1.10.0
```



开发流程：

* 搭建批处理执行环境；
* 读取数据；
* 进行转换操作；
* 执行程序；



```
public static void main(String[] args) throws Exception {
        String fs = "D:/Storage/dev/wordcount/input/words.txt";
        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
        DataSource<String> text = env.readTextFile(fs);
        text.flatMap(new FlatMapFunction<String, Tuple2<String, Integer>>() {
            @Override
            public void flatMap(String line, Collector<Tuple2<String, Integer>> collector) throws Exception {
                String[] tokens = line.toLowerCase().split(" ");
                for (String token:tokens) {
                    if (token.length() > 0) {
                        collector.collect(new Tuple2<>(token, 1));
                    }
                }
            }
        }).groupBy(0).sum(1).print();
}
```

**注意**：在本地单机运行时，`pom`文件中的依赖项的`scope`的`provided`注释掉，否则会报错：找不到相关类。



```
<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-java</artifactId>
			<version>${flink.version}</version>
<!--			<scope>provided</scope>-->
		</dependency>
		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-streaming-java_${scala.binary.version}</artifactId>
			<version>${flink.version}</version>
<!--			<scope>provided</scope>-->
		</dependency>
```



#### Scala语言批处理应用

**注意**：`import org.apache.flink.api.scala._`必须要写

工程创建：

```
利用IDEA创建maven工程：

GroupId=org.apache.flink
ArtifactId=flink-quickstart-scala
Version=1.10.0
```



```
  def main(args: Array[String]): Unit = {
    val input = "D:/Storage/dev/wordcount/input/words.txt"
    val env = ExecutionEnvironment.getExecutionEnvironment
    val text = env.readTextFile(input)
    import org.apache.flink.api.scala._
    text.flatMap(_.toLowerCase.split(" ")).filter(_.nonEmpty).map((_, 1)).groupBy(0).sum(1).print()
  }
```

**注意**：在本地单机运行时，`pom`文件中的依赖项的`scope`的`provided`注释掉，否则会报错：找不到相关类。



```
<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-scala_${scala.binary.version}</artifactId>
			<version>${flink.version}</version>
<!--			<scope>provided</scope>-->
		</dependency>
		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-streaming-scala_${scala.binary.version}</artifactId>
			<version>${flink.version}</version>
<!--			<scope>provided</scope>-->
		</dependency>

		<!-- Scala Library, provided by Flink as well. -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
<!--			<scope>provided</scope>-->
		</dependency>
```



#### Java语言流处理应用



```
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        DataStreamSource<String> text = env.socketTextStream("192.168.0.108", 9999);
        text.flatMap(new FlatMapFunction<String, Tuple2<String, Integer>>() {
            @Override
            public void flatMap(String line, Collector<Tuple2<String, Integer>> collector) throws Exception {
                String[] tokens = line.toLowerCase().split(" ");
                for (String token:tokens) {
                    if (token.length() > 0) {
                        collector.collect(new Tuple2<>(token, 1));
                    }
                }
            }
        }).keyBy(0).timeWindow(Time.seconds(5)).sum(1).print();
        // timeWindow 指定多久执行一次
        env.execute("StreamingJava"); // 流处理应用一定要执行该语句
    }
```



注：流处理应用会指定多久执行一次相关操作；

通过`nc -lk 9999`命令开启`socket`；



#### Scala语言流处理应用

```
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    val text = env.socketTextStream("192.168.0.108", 9999)
    import org.apache.flink.api.scala._
    text.flatMap(_.split(" "))
      .map((_, 1))
      .keyBy(0)
      .timeWindow(Time.seconds(5))
      .sum(1)
      .print()
      .setParallelism(1)
    env.execute("StreamingScala")
  }
```

